{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a5358-f928-4b7f-a32d-a4c7b69cba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.image_processing import ImageProcessor\n",
    "from src.tiles_segmentation import TileExtractor\n",
    "from src.tiles_classification import TileClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab797a3-39c8-4221-ae6b-a08dd75a9895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "    if title is not None:\n",
    "        fig.suptitle(title)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea30e6-d612-4bd4-b61a-24eeee43ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/Pict_4_1.bmp')\n",
    "#image = cv2.cvtColor(image_orig, cv2.COLOR_BGR2GRAY)\n",
    "#image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "show(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e3f68-26b2-4791-af7e-b93b420f2b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_image_otsu = proc.process_image(image, 'otsu')\n",
    "thres_image_ada = proc.process_image(image, 'adaptive')\n",
    "\n",
    "contours_otsu, _ = cv2.findContours(thres_image_otsu,\n",
    "                                    cv2.RETR_LIST,\n",
    "                                    cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours_ada, _ = cv2.findContours(thres_image_ada,\n",
    "                                   cv2.RETR_LIST,\n",
    "                                   cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "contours_otsu = proc.process_contours(contours_otsu)\n",
    "contours_ada = proc.process_contours(contours_ada)\n",
    "\n",
    "unique_contours = proc.find_unique_contours(contours_otsu + contours_ada)\n",
    "\n",
    "output_image = image.copy()\n",
    "cv2.drawContours(output_image, [c.vertices for c in unique_contours], -1, (0, 255, 0), 2)\n",
    "\n",
    "show(output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8fe79-9c17-4d26-955b-df0c504231c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(12, 12))\n",
    "ax = iter(ax.flatten())\n",
    "\n",
    "for img_path in os.listdir('images'):\n",
    "    if img_path.startswith('Pict'):\n",
    "        image = cv2.imread(os.path.join('images/', img_path))\n",
    "        assert image is not None, 'bad image'\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        axes = next(ax)\n",
    "\n",
    "        proc = TileExtractor(area_min=2000,\n",
    "                              min_dist_between_centr=20,\n",
    "                              approx_thres=0.05,\n",
    "                              equilaterial_thres=0.15)\n",
    "        contr = proc.find_objects(image)\n",
    "        output_image = image.copy()\n",
    "        cv2.drawContours(output_image, [c.vertices for c in contr], -1, (0, 255, 0), 2)\n",
    "        show(output_image, axes)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e3dab-f4c7-4c38-96c0-45be0b4c0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = ImageProcessor()\n",
    "proc.process_image('./images/Pict_2_2.bmp', 'Pict_2_2.info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2230dfe0-834b-4eef-af6b-80e6738a9e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/Pict_2_2.bmp')\n",
    "show(image)\n",
    "\n",
    "classifier = TileClassifier(center_dist_thres=4,\n",
    "                           min_dot_r=2.5,\n",
    "                           max_dot_r=6)\n",
    "ext = TileExtractor(area_min=2000,\n",
    "                      min_dist_between_centr=20,\n",
    "                      approx_thres=0.05,\n",
    "                      equilaterial_thres=0.15)\n",
    "contours = ext.find_objects(image)\n",
    "\n",
    "for cropped in proc.extract_tile_images(image, contours):\n",
    "    show(cropped, title=str(classifier.predict(cropped)) + f' {np.mean(cropped)}')\n",
    "    #print(classifier.predict(cropped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fa5654-25f6-4900-8559-8cde64eafdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "centr_clrs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd89efa-7e06-4d4a-957b-17f543c855ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cropped[size // 2:, size // 2:]\n",
    "def classify(img):\n",
    "    chs_bgr = list(cv2.split(img))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    chs = list(cv2.split(img))\n",
    "    chs.append(255 - chs[1])\n",
    "    # chs += [255 - ch for ch in chs]\n",
    "    # chs += chs_bgr\n",
    "    # chs += [255 - ch for ch in chs_bgr]\n",
    "    #chs = [cv2.split(img)[1]]\n",
    "    thresh = np.zeros_like(chs[0])\n",
    "    for ch in chs:\n",
    "        ch = cv2.medianBlur(ch, 3)\n",
    "        #ch = cv2.GaussianBlur(ch, (3, 3), 0)\n",
    "\n",
    "        # se=cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        # bg=cv2.morphologyEx(ch, cv2.MORPH_DILATE, se)\n",
    "        # ch=cv2.divide(ch, bg, scale=255)\n",
    "        #show(ch)\n",
    "\n",
    "        # t = cv2.adaptiveThreshold(ch, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        #                                cv2.THRESH_BINARY_INV, 3, 2)\n",
    "        #_, t = cv2.threshold(ch, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        #t = cv2.erode(t, (2, 2), iterations=2)\n",
    "        #t = cv2.dilate(t, (3, 3), iterations=2)\n",
    "        #t = cv2.morphologyEx(t, cv2.MORPH_OPEN, (3, 3), iterations=1)\n",
    "        #show(ch)\n",
    "        t = cv2.Canny(ch, 70, 110)\n",
    "        #show(t)\n",
    "        thresh = cv2.bitwise_or(thresh, t)\n",
    "    show(thresh)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    output_mask = np.zeros_like(img)\n",
    "    segmentated_dots = []\n",
    "    for contour in contours:\n",
    "        r = np.random.randint(50, 150)\n",
    "        g = np.random.randint(50, 255 - r)\n",
    "        b = 255 - r - g\n",
    "        (x,y),r = cv2.minEnclosingCircle(contour)\n",
    "        center = (int(x),int(y))\n",
    "        dsts = [math.sqrt((center[0] - pt[0])**2 + (center[1] - pt[1])**2) for pt in segmentated_dots]\n",
    "        if 2.5 < r < 6 and (len(dsts) == 0 or min(dsts) > 4):\n",
    "            #centr_clrs.append(img[int(y), int(x)])\n",
    "            cv2.drawContours(output_mask, [contour], -1, (r, g, b), 2)\n",
    "            segmentated_dots.append(center)\n",
    "    return output_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06c3737-bf5c-41f0-8aca-ae17e4db9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_guess(image, guess) -> bool:\n",
    "    channels_by_guess = {\n",
    "        1: [7, 10],\n",
    "        2: [1, 2, 4, 8],\n",
    "        3: [2, 5],\n",
    "        4: [1, 2, 4, 5],\n",
    "        5: [7, 10],\n",
    "    }\n",
    "\n",
    "    chs_bgr = list(cv2.split(image))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    chs = list(cv2.split(image))\n",
    "    chs += [255 - ch for ch in chs]\n",
    "    chs += chs_bgr\n",
    "    chs += [255 - ch for ch in chs_bgr]\n",
    "\n",
    "    chs = np.array(chs)[channels_by_guess[guess]]\n",
    "    thresh = np.zeros_like(chs[0])\n",
    "\n",
    "    for ch in chs:\n",
    "        ch = cv2.medianBlur(ch, 3)\n",
    "        t = cv2.Canny(ch, 70, 120)\n",
    "        thresh = cv2.bitwise_or(thresh, t)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    segmentated_dots = []\n",
    "    for contour in contours:\n",
    "        (x, y), r = cv2.minEnclosingCircle(contour)\n",
    "        center = (int(x), int(y))\n",
    "        dsts = [math.sqrt((center[0] - pt[0])**2 + (center[1] - pt[1])**2) for pt in segmentated_dots]\n",
    "        if 1 < r < 7 and (len(dsts) == 0 or min(dsts) > 5):\n",
    "            segmentated_dots.append(center)\n",
    "\n",
    "    if guess == 5:\n",
    "        show(thresh, title=f'guess={guess}, found={len(segmentated_dots)}')\n",
    "    return len(segmentated_dots) == guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f4c80a-726f-4a73-8093-6fa0dd56d34f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/Pict_2_2.bmp')\n",
    "image = (image / 255)\n",
    "image[image > 1] = 1\n",
    "image = (image * 255).astype(np.uint8)\n",
    "\n",
    "proc = ImageProcessor()\n",
    "ext = TileExtractor(area_min=2000,\n",
    "                      min_dist_between_centr=20,\n",
    "                      approx_thres=0.05,\n",
    "                      equilaterial_thres=0.15)\n",
    "contours = ext.find_objects(image)\n",
    "\n",
    "for cropped in proc.extract_tile_images(image, contours):\n",
    "    size = cropped.shape[0]\n",
    "    clusters = [cropped[:size // 2, size // 4:size - size//4],\n",
    "                cropped[size // 2:, :size // 2],\n",
    "                cropped[size // 2:, size // 2:]]\n",
    "    for c in clusters:\n",
    "        ans = 0\n",
    "        for i in range(1, 6):\n",
    "            if try_guess(c, i):\n",
    "                ans = i\n",
    "                break\n",
    "        show(c, title=ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae122b-4784-44f4-8754-78eb2cd8eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/Pict_1_1.bmp')\n",
    "# image = (image / 255) * 1.3\n",
    "# image[image > 1] = 1\n",
    "# image = (image * 255).astype(np.uint8)\n",
    "\n",
    "proc = TileExtractor(area_min=2000,\n",
    "                      min_dist_between_centr=20,\n",
    "                      approx_thres=0.05,\n",
    "                      equilaterial_thres=0.15)\n",
    "contr = proc.find_objects(image)\n",
    "for c in contr[1:]:\n",
    "    # find <<bottom>> side of the triangle\n",
    "    a, b = sorted(c.vertices[:, 0], key=lambda x: x[1], reverse=True)[:2]\n",
    "    x, y = a - b\n",
    "\n",
    "    # rotate image so the triangle will stand upright\n",
    "    angle = np.degrees(np.arctan2(y, x))\n",
    "    angle = angle if angle < 90 else angle + 180\n",
    "    center = (c.centroid.x, c.centroid.y)\n",
    "\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "    rot = cv2.transform(c.vertices, M)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(rot)\n",
    "    size = max(w, h)\n",
    "    cropped = rotated[y:y + size, x:x + size]\n",
    "    clusters = [cropped[:size // 2, size // 4:size - size//4],\n",
    "                cropped[size // 2:, :size // 2],\n",
    "                cropped[size // 2:, size // 2:]]\n",
    "    show(cropped)\n",
    "    for c in clusters:\n",
    "        print(np.mean(c))\n",
    "        show(classify(c))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6f05ee-fc02-4d3d-87ba-98d52d8176a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "clrs = np.array(centr_clrs)\n",
    "clrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec8e3ba-bdcc-4a20-a17f-b9ce96585a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=6, metric='cosine')\n",
    "model.fit(clrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf56073-5807-48f5-837f-f300e587cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d6f601-c932-42a4-a2fb-6abfc1013ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embed = TSNE(perplexity=10).fit_transform(clrs)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].scatter(*embed.T, c=clrs / 255)\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "ax[1].scatter(*embed.T, c=model.labels_)\n",
    "ax[1].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8532b78e-07c0-4b08-bbd3-6f3d2c4b2d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(image):\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69670dff-d652-44b9-afe4-14f2746728f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_dots(contour):\n",
    "    # Approximate the contour to a polygon\n",
    "    peri = cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, 0.05 * peri, True)\n",
    "    \n",
    "    # If the polygon has 3 vertices, it's a triangle\n",
    "    if len(approx) == 3:\n",
    "        # Compute centroid of the contour\n",
    "        M = cv2.moments(contour)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "\n",
    "        return (cx, cy), approx\n",
    "\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef99805-0c93-40f1-bab7-b19e8c0a53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    # clahe = cv2.createCLAHE(clipLimit=2, tileGridSize=(30, 30))\n",
    "    # image = clahe.apply(image)\n",
    "\n",
    "    # Apply Gaussian blur to remove noise\n",
    "    image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    image = cv2.medianBlur(image, 15)\n",
    "\n",
    "    se=cv2.getStructuringElement(cv2.MORPH_RECT, (10, 10))\n",
    "    bg=cv2.morphologyEx(image, cv2.MORPH_DILATE, se)\n",
    "    image=cv2.divide(image, bg, scale=255)\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    _, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    #show(thresh)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, (3, 3), iterations=2)\n",
    "    #thresh = cv2.erode(thresh, (3, 3), iterations=2)\n",
    "    #thresh = cv2.dilate(thresh, (5, 5), iterations=2)\n",
    "    show(thresh)\n",
    "\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6db666-e75a-4516-9c89-5797240d3558",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/Pict_2_1.bmp')\n",
    "\n",
    "# Preprocess the image\n",
    "output_image = None\n",
    "for ch in cv2.split(image):\n",
    "    if output_image is None:\n",
    "        output_image = np.zeros_like(ch)\n",
    "    processed_image = preprocess_image(ch)\n",
    "    output_image = cv2.bitwise_or(output_image, processed_image)\n",
    "#output_image = cv2.morphologyEx(output_image, cv2.MORPH_OPEN, (3, 3), iterations=5)\n",
    "#output_image = cv2.erode(output_image, (3, 3), iterations=1)\n",
    "show(output_image)\n",
    "# Find contours\n",
    "contours = find_contours(output_image.copy())\n",
    "\n",
    "output_mask = np.zeros_like(image)\n",
    "cv2.drawContours(output_mask, contours, -1, (0, 255, 0), 2)\n",
    "show(output_mask)\n",
    "\n",
    "# Create a copy of the original image to draw results\n",
    "output_mask = np.zeros_like(image)\n",
    "output_image = image.copy()\n",
    "\n",
    "# List to store centroids and dot counts\n",
    "centroids_validated = []\n",
    "contours_validated = []\n",
    "\n",
    "for contour in contours:\n",
    "    dot_coords, approx = count_dots(contour)\n",
    "    if dot_coords:\n",
    "        centroids_validated.append(dot_coords)\n",
    "        contours_validated.append(approx)\n",
    "cv2.drawContours(output_image, contours_validated, -1, (0, 255, 0), 2)\n",
    "cv2.drawContours(output_mask, contours_validated, -1, (0, 255, 0), 2)\n",
    "show(output_mask)\n",
    "show(output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68765209-e512-41b3-a945-49593442a0bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contour = contours\n",
    "\n",
    "output_image = image.copy()\n",
    "\n",
    "# List to store centroids and dot counts\n",
    "centroids_validated = []\n",
    "contours_validated = []\n",
    "\n",
    "for contour in contours:\n",
    "    dot_coords, approx = count_dots(contour)\n",
    "    if dot_coords:\n",
    "        centroids_validated.append(dot_coords)\n",
    "        contours_validated.append(approx)\n",
    "cv2.drawContours(output_image, contours_validated, -1, (0, 255, 0), 2)\n",
    "show(output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74168bdb-414d-47c2-b4f9-2c8b5418bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "output_image = preprocess_image(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "#output_image = cv2.morphologyEx(output_image, cv2.MORPH_OPEN, (3, 3), iterations=1)\n",
    "#output_image = cv2.dilate(output_image, (15, 15), iterations=8)\n",
    "show(output_image)\n",
    "# Find contours\n",
    "contours = find_contours(output_image.copy())\n",
    "\n",
    "output_mask = np.zeros_like(image)\n",
    "cv2.drawContours(output_mask, contours, -1, (0, 255, 0), 2)\n",
    "show(output_mask)\n",
    "\n",
    "# Create a copy of the original image to draw results\n",
    "output_mask = np.zeros_like(image)\n",
    "output_image = image.copy()\n",
    "\n",
    "# List to store centroids and dot counts\n",
    "centroids_validated = []\n",
    "contours_validated = []\n",
    "\n",
    "for contour in contours:\n",
    "    dot_coords, approx = count_dots(contour)\n",
    "    if dot_coords:\n",
    "        centroids_validated.append(dot_coords)\n",
    "        contours_validated.append(approx)\n",
    "cv2.drawContours(output_image, contours_validated, -1, (0, 255, 0), 2)\n",
    "cv2.drawContours(output_mask, contours_validated, -1, (0, 255, 0), 2)\n",
    "show(output_mask)\n",
    "show(output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d6af10-ea26-4b4a-8234-24ca6078931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_orig = cv2.imread('./images/Pict_3_2.bmp')\n",
    "image = cv2.cvtColor(image_orig, cv2.COLOR_BGR2GRAY)\n",
    "image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))\n",
    "\n",
    "edges = cv2.Canny(image, 50, 100)\n",
    "show(edges)\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# create a blank mask to store the segmented objects\n",
    "mask = image_orig.copy()\n",
    "fill_color = (0, 255, 0)\n",
    "\n",
    "cv2.drawContours(mask, contours, -1, fill_color, 2)\n",
    "show(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80c42d-1cb8-4523-9fa1-28bda0093e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image = None\n",
    "for ch in cv2.split(image):\n",
    "    if output_image is None:\n",
    "        output_image = np.zeros_like(ch)\n",
    "    processed_image = preprocess_image(ch)\n",
    "    output_image = cv2.bitwise_or(output_image, processed_image)\n",
    "show(output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d246273-a849-4c83-bfe0-bf10e328c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default_color(image, target_color, threshold, default_color):\n",
    "    \n",
    "    # Define lower and upper bounds for the target color in LAB color space\n",
    "    lower_bound = (target_color - threshold).astype(np.uint8)\n",
    "    upper_bound = (target_color + threshold).astype(np.uint8)\n",
    "    \n",
    "    # Create a mask for pixels within the target color range\n",
    "    mask = cv2.inRange(image, lower_bound, upper_bound)\n",
    "\n",
    "    # Invert the mask\n",
    "    mask = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Set the color of pixels outside the target color range to default color\n",
    "    image[mask == 255] = default_color\n",
    "    \n",
    "    return image\n",
    "\n",
    "target_color = np.array((107, 69, 48))\n",
    "threshold = np.array((30, 10, 10))\n",
    "default_color = np.array((255, 255, 255))\n",
    "show(set_default_color(image.copy(), target_color, threshold, default_color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad0957-3518-46f2-b473-8f0acb6657b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split image into channels\n",
    "b, g, r = cv2.split(image_orig)\n",
    "\n",
    "# Compute absolute differences for each channel\n",
    "diff_b = cv2.absdiff(b, cv2.medianBlur(b, 5))\n",
    "diff_g = cv2.absdiff(g, cv2.medianBlur(g, 5))\n",
    "diff_r = cv2.absdiff(r, cv2.medianBlur(r, 5))\n",
    "\n",
    "# Combine differences\n",
    "diff = cv2.bitwise_or(cv2.bitwise_or(diff_b, diff_g), diff_r)\n",
    "\n",
    "# Threshold the combined difference image\n",
    "_, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_OTSU)\n",
    "show(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8aee96-12e2-4f21-964e-d9f643205e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
